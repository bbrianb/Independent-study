{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T02:59:57.045030Z",
     "start_time": "2025-01-15T02:59:57.040094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.__version__, pd.__version__"
   ],
   "id": "c4355ee59f709f65",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.26.4', '2.2.3')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T02:59:57.054119Z",
     "start_time": "2025-01-15T02:59:57.049025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ],
   "id": "b5c9fdc734499ea1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T02:59:57.391440Z",
     "start_time": "2025-01-15T02:59:57.056118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LoanDataset(Dataset):\n",
    "    def __init__(self, current_slice):\n",
    "        df = pd.read_csv('data/loan_data.csv')\n",
    "\n",
    "        # Convert non-numeric columns to numeric\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            df[col] = df[col].astype('category').cat.codes  # Label encode strings\n",
    "\n",
    "        # Convert to numpy\n",
    "        xy = df.to_numpy()\n",
    "        self.x = torch.from_numpy(xy[current_slice, :-1]).float()  # all columns except last\n",
    "        self.y = torch.from_numpy(xy[current_slice, [-1]]).float()\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "split = int(0.8*45000)\n",
    "trainData = LoanDataset(slice(None,split))\n",
    "testData = LoanDataset(slice(split,None))\n",
    "pct = .8\n",
    "trainDataLoader = DataLoader(dataset=trainData, batch_size=45)\n",
    "testDataLoader = DataLoader(dataset=testData, batch_size=45)\n",
    "trainData[0], trainData[4], testData[0]"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([2.2000e+01, 0.0000e+00, 4.0000e+00, 7.1948e+04, 0.0000e+00, 3.0000e+00,\n",
       "          3.5000e+04, 4.0000e+00, 1.6020e+01, 4.9000e-01, 3.0000e+00, 5.6100e+02,\n",
       "          0.0000e+00]),\n",
       "  tensor([1.])),\n",
       " (tensor([2.4000e+01, 1.0000e+00, 4.0000e+00, 6.6135e+04, 1.0000e+00, 3.0000e+00,\n",
       "          3.5000e+04, 3.0000e+00, 1.4270e+01, 5.3000e-01, 4.0000e+00, 5.8600e+02,\n",
       "          0.0000e+00]),\n",
       "  tensor([1.])),\n",
       " (tensor([2.4000e+01, 1.0000e+00, 3.0000e+00, 3.9534e+04, 4.0000e+00, 2.0000e+00,\n",
       "          3.5140e+03, 3.0000e+00, 1.4190e+01, 9.0000e-02, 3.0000e+00, 6.2600e+02,\n",
       "          1.0000e+00]),\n",
       "  tensor([0.])))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T02:59:58.279389Z",
     "start_time": "2025-01-15T02:59:57.393413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(13, 20),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n",
    "    \n",
    "def accuracy(targets, predictions):\n",
    "    correct = torch.eq(targets, predictions).sum().item()\n",
    "    return correct / len(targets)\n",
    "\n",
    "model = Model()\n",
    "lossFun = nn.BCEWithLogitsLoss()\n",
    "losses = torch.tensor([])\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    trainLoss = 0\n",
    "    for batch, (X, y) in enumerate(trainDataLoader):\n",
    "        model.train()\n",
    "        yPred = model(X)\n",
    "        loss = lossFun(yPred, y)\n",
    "        trainLoss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 10 == 0:\n",
    "            print(f'{epoch=}, {batch=}')\n",
    "    trainLoss /= len(trainDataLoader)\n",
    "    \n",
    "    testLoss = 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for XTest, yTest in testDataLoader:\n",
    "            testPred = model(XTest)\n",
    "            testLoss += lossFun(testPred, yTest)\n",
    "        testLoss /= len(testDataLoader)\n",
    "    print(f'{epoch=}, {trainLoss=}, {testLoss=}')"
   ],
   "id": "ff50f2d7f2d4430a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, batch=0\n",
      "epoch=0, batch=10\n",
      "epoch=0, batch=20\n",
      "epoch=0, batch=30\n",
      "epoch=0, batch=40\n",
      "epoch=0, batch=50\n",
      "epoch=0, batch=60\n",
      "epoch=0, batch=70\n",
      "epoch=0, batch=80\n",
      "epoch=0, batch=90\n",
      "epoch=0, batch=100\n",
      "epoch=0, batch=110\n",
      "epoch=0, batch=120\n",
      "epoch=0, batch=130\n",
      "epoch=0, batch=140\n",
      "epoch=0, batch=150\n",
      "epoch=0, batch=160\n",
      "epoch=0, batch=170\n",
      "epoch=0, batch=180\n",
      "epoch=0, batch=190\n",
      "epoch=0, batch=200\n",
      "epoch=0, batch=210\n",
      "epoch=0, batch=220\n",
      "epoch=0, batch=230\n",
      "epoch=0, batch=240\n",
      "epoch=0, batch=250\n",
      "epoch=0, batch=260\n",
      "epoch=0, batch=270\n",
      "epoch=0, batch=280\n",
      "epoch=0, batch=290\n",
      "epoch=0, batch=300\n",
      "epoch=0, batch=310\n",
      "epoch=0, batch=320\n",
      "epoch=0, batch=330\n",
      "epoch=0, batch=340\n",
      "epoch=0, batch=350\n",
      "epoch=0, batch=360\n",
      "epoch=0, batch=370\n",
      "epoch=0, batch=380\n",
      "epoch=0, batch=390\n",
      "epoch=0, batch=400\n",
      "epoch=0, batch=410\n",
      "epoch=0, batch=420\n",
      "epoch=0, batch=430\n",
      "epoch=0, batch=440\n",
      "epoch=0, batch=450\n",
      "epoch=0, batch=460\n",
      "epoch=0, batch=470\n",
      "epoch=0, batch=480\n",
      "epoch=0, batch=490\n",
      "epoch=0, batch=500\n",
      "epoch=0, batch=510\n",
      "epoch=0, batch=520\n",
      "epoch=0, batch=530\n",
      "epoch=0, batch=540\n",
      "epoch=0, batch=550\n",
      "epoch=0, batch=560\n",
      "epoch=0, batch=570\n",
      "epoch=0, batch=580\n",
      "epoch=0, batch=590\n",
      "epoch=0, batch=600\n",
      "epoch=0, batch=610\n",
      "epoch=0, batch=620\n",
      "epoch=0, batch=630\n",
      "epoch=0, batch=640\n",
      "epoch=0, batch=650\n",
      "epoch=0, batch=660\n",
      "epoch=0, batch=670\n",
      "epoch=0, batch=680\n",
      "epoch=0, batch=690\n",
      "epoch=0, batch=700\n",
      "epoch=0, batch=710\n",
      "epoch=0, batch=720\n",
      "epoch=0, batch=730\n",
      "epoch=0, batch=740\n",
      "epoch=0, batch=750\n",
      "epoch=0, batch=760\n",
      "epoch=0, batch=770\n",
      "epoch=0, batch=780\n",
      "epoch=0, batch=790\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 36000 is out of bounds for dimension 0 with size 36000",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[130], line 24\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m     23\u001B[0m     trainLoss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 24\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch, (X, y) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(trainDataLoader):\n\u001B[0;32m     25\u001B[0m         model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     26\u001B[0m         yPred \u001B[38;5;241m=\u001B[39m model(X)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[1;32mIn[129], line 16\u001B[0m, in \u001B[0;36mLoanDataset.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index):\n\u001B[1;32m---> 16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx[index], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my[index]\n",
      "\u001B[1;31mIndexError\u001B[0m: index 36000 is out of bounds for dimension 0 with size 36000"
     ]
    }
   ],
   "execution_count": 130
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
