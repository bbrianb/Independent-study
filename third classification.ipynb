{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28edc5f42785b9ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T23:52:08.879266Z",
     "start_time": "2024-11-20T23:52:04.898559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T23:52:19.705642Z",
     "start_time": "2024-11-20T23:52:08.880338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([45000, 13]), torch.Size([45000]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import torch\n",
    "fileName = 'data/loan_data.csv'\n",
    "\n",
    "with open(fileName) as csvFile:\n",
    "    reader = csv.reader(csvFile)\n",
    "    variables = next(reader)\n",
    "    columnInfo = [[] for _ in range(len(variables))]\n",
    "    data = torch.tensor([])\n",
    "    labels = torch.tensor([])\n",
    "    for row in reader:\n",
    "        temp = torch.zeros(1, len(variables) - 1)\n",
    "        for columnIndex, column in enumerate(row[:-1]):\n",
    "            try:\n",
    "                value = float(column)\n",
    "            except ValueError:\n",
    "                if column not in columnInfo[columnIndex]:\n",
    "                    columnInfo[columnIndex].append(column)\n",
    "                value = columnInfo[columnIndex].index(column)\n",
    "            if value != 0:\n",
    "                value = value ** -1\n",
    "            temp[0][columnIndex] = value\n",
    "        data = torch.cat((data, temp))\n",
    "        labels = torch.cat((labels, torch.tensor([int(row[-1])])))\n",
    "labels = labels\n",
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cb129a90e9b70b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T23:52:20.173722Z",
     "start_time": "2024-11-20T23:52:19.706638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_gender</th>\n",
       "      <th>person_education</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_exp</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>previous_loan_defaults_on_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.062422</td>\n",
       "      <td>2.040816</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.089767</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.077700</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.065660</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.070077</td>\n",
       "      <td>1.886792</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44995</th>\n",
       "      <td>0.037037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.063857</td>\n",
       "      <td>3.225806</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44996</th>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.071073</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44997</th>\n",
       "      <td>0.030303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.099800</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44998</th>\n",
       "      <td>0.034483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.075586</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44999</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.058651</td>\n",
       "      <td>7.692307</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_age  person_gender  person_education  person_income  \\\n",
       "0        0.045455            0.0          0.000000       0.000014   \n",
       "1        0.047619            0.0          1.000000       0.000081   \n",
       "2        0.040000            0.0          1.000000       0.000080   \n",
       "3        0.043478            0.0          0.500000       0.000013   \n",
       "4        0.041667            1.0          0.000000       0.000015   \n",
       "...           ...            ...               ...            ...   \n",
       "44995    0.037037            1.0          0.333333       0.000021   \n",
       "44996    0.027027            0.0          0.333333       0.000015   \n",
       "44997    0.030303            1.0          0.333333       0.000018   \n",
       "44998    0.034483            1.0          0.500000       0.000030   \n",
       "44999    0.041667            1.0          1.000000       0.000019   \n",
       "\n",
       "       person_emp_exp  person_home_ownership  loan_amnt  loan_intent  \\\n",
       "0            0.000000                    0.0   0.000029         0.00   \n",
       "1            0.000000                    1.0   0.001000         1.00   \n",
       "2            0.333333                    0.5   0.000182         0.50   \n",
       "3            0.000000                    0.0   0.000029         0.50   \n",
       "4            1.000000                    0.0   0.000029         0.50   \n",
       "...               ...                    ...        ...          ...   \n",
       "44995        0.166667                    0.0   0.000067         0.50   \n",
       "44996        0.058824                    0.0   0.000111         0.25   \n",
       "44997        0.142857                    0.0   0.000361         0.20   \n",
       "44998        0.250000                    0.0   0.000083         1.00   \n",
       "44999        1.000000                    0.0   0.000150         0.20   \n",
       "\n",
       "       loan_int_rate  loan_percent_income  cb_person_cred_hist_length  \\\n",
       "0           0.062422             2.040816                    0.333333   \n",
       "1           0.089767            12.500000                    0.500000   \n",
       "2           0.077700             2.272727                    0.333333   \n",
       "3           0.065660             2.272727                    0.500000   \n",
       "4           0.070077             1.886792                    0.250000   \n",
       "...              ...                  ...                         ...   \n",
       "44995       0.063857             3.225806                    0.333333   \n",
       "44996       0.071073             7.142857                    0.090909   \n",
       "44997       0.099800            20.000000                    0.100000   \n",
       "44998       0.075586             2.777778                    0.166667   \n",
       "44999       0.058651             7.692307                    0.333333   \n",
       "\n",
       "       credit_score  previous_loan_defaults_on_file  \n",
       "0          0.001783                             0.0  \n",
       "1          0.001984                             1.0  \n",
       "2          0.001575                             0.0  \n",
       "3          0.001481                             0.0  \n",
       "4          0.001706                             0.0  \n",
       "...             ...                             ...  \n",
       "44995      0.001550                             0.0  \n",
       "44996      0.001610                             0.0  \n",
       "44997      0.001497                             0.0  \n",
       "44998      0.001656                             0.0  \n",
       "44999      0.001592                             0.0  \n",
       "\n",
       "[45000 rows x 13 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "df = df.set_axis(variables[:-1], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "948933f39b0ddeb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T23:52:20.326533Z",
     "start_time": "2024-11-20T23:52:20.174716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([36000, 13]),\n",
       " torch.Size([9000, 13]),\n",
       " torch.Size([36000]),\n",
       " torch.Size([9000]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct = .8\n",
    "XSplit = int(pct*len(data))\n",
    "ySplit = int(pct * len(labels))\n",
    "XTrain, XTest = data[:XSplit].to(device), data[XSplit:].to(device)\n",
    "yTrain, yTest = labels[:ySplit].to(device), labels[ySplit:].to(device)\n",
    "XTrain.shape, XTest.shape, yTrain.shape, yTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "475ca1adbe7b3abb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T23:52:20.638835Z",
     "start_time": "2024-11-20T23:52:20.327529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4.5455e-02, 0.0000e+00, 0.0000e+00, 1.3899e-05, 0.0000e+00, 0.0000e+00,\n",
       "          2.8571e-05, 0.0000e+00, 6.2422e-02, 2.0408e+00, 3.3333e-01, 1.7825e-03,\n",
       "          0.0000e+00],\n",
       "         [4.7619e-02, 0.0000e+00, 1.0000e+00, 8.1420e-05, 0.0000e+00, 1.0000e+00,\n",
       "          1.0000e-03, 1.0000e+00, 8.9767e-02, 1.2500e+01, 5.0000e-01, 1.9841e-03,\n",
       "          1.0000e+00],\n",
       "         [4.0000e-02, 0.0000e+00, 1.0000e+00, 8.0399e-05, 3.3333e-01, 5.0000e-01,\n",
       "          1.8182e-04, 5.0000e-01, 7.7700e-02, 2.2727e+00, 3.3333e-01, 1.5748e-03,\n",
       "          0.0000e+00],\n",
       "         [4.3478e-02, 0.0000e+00, 5.0000e-01, 1.2539e-05, 0.0000e+00, 0.0000e+00,\n",
       "          2.8571e-05, 5.0000e-01, 6.5660e-02, 2.2727e+00, 5.0000e-01, 1.4815e-03,\n",
       "          0.0000e+00],\n",
       "         [4.1667e-02, 1.0000e+00, 0.0000e+00, 1.5121e-05, 1.0000e+00, 0.0000e+00,\n",
       "          2.8571e-05, 5.0000e-01, 7.0077e-02, 1.8868e+00, 2.5000e-01, 1.7065e-03,\n",
       "          0.0000e+00]], device='cuda:0'),\n",
       " tensor([1., 0., 1., 1., 1.], device='cuda:0'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain[0:5], yTrain[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ae6a24b124633f77",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     0 | Train loss: 0.6145 | Test loss: 0.5854  | Test acc: 67.8222%\n",
      "Epoch:   100 | Train loss: 0.3656 | Test loss: 0.4702  | Test acc: 68.3778%\n",
      "Epoch:   200 | Train loss: 0.3912 | Test loss: 0.3955  | Test acc: 83.7556%\n",
      "Epoch:   300 | Train loss: 0.3674 | Test loss: 0.3698  | Test acc: 83.4333%\n",
      "Epoch:   400 | Train loss: 0.3518 | Test loss: 0.3578  | Test acc: 83.4222%\n",
      "Epoch:   500 | Train loss: 0.3413 | Test loss: 0.3509  | Test acc: 83.5333%\n",
      "Epoch:   600 | Train loss: 0.3337 | Test loss: 0.3464  | Test acc: 83.4778%\n",
      "Epoch:   700 | Train loss: 0.3280 | Test loss: 0.3432  | Test acc: 83.5111%\n",
      "Epoch:   800 | Train loss: 0.3236 | Test loss: 0.3409  | Test acc: 83.6111%\n",
      "Epoch:   900 | Train loss: 0.3200 | Test loss: 0.3391  | Test acc: 83.5889%\n",
      "Epoch:  1000 | Train loss: 0.3170 | Test loss: 0.3378  | Test acc: 83.6000%\n",
      "Epoch:  1100 | Train loss: 0.3146 | Test loss: 0.3367  | Test acc: 83.5889%\n",
      "Epoch:  1200 | Train loss: 0.3125 | Test loss: 0.3358  | Test acc: 83.5889%\n",
      "Epoch:  1300 | Train loss: 0.3107 | Test loss: 0.3350  | Test acc: 83.5667%\n",
      "Epoch:  1400 | Train loss: 0.3091 | Test loss: 0.3344  | Test acc: 83.5444%\n",
      "Epoch:  1500 | Train loss: 0.3077 | Test loss: 0.3339  | Test acc: 83.5444%\n",
      "Epoch:  1600 | Train loss: 0.3065 | Test loss: 0.3335  | Test acc: 83.5667%\n",
      "Epoch:  1700 | Train loss: 0.3055 | Test loss: 0.3331  | Test acc: 83.5556%\n",
      "Epoch:  1800 | Train loss: 0.3045 | Test loss: 0.3328  | Test acc: 83.5778%\n",
      "Epoch:  1900 | Train loss: 0.3036 | Test loss: 0.3325  | Test acc: 83.5556%\n",
      "Epoch:  2000 | Train loss: 0.3029 | Test loss: 0.3323  | Test acc: 83.5778%\n",
      "Epoch:  2100 | Train loss: 0.3022 | Test loss: 0.3321  | Test acc: 83.5667%\n",
      "Epoch:  2200 | Train loss: 0.3015 | Test loss: 0.3319  | Test acc: 83.5889%\n",
      "Epoch:  2300 | Train loss: 0.3009 | Test loss: 0.3317  | Test acc: 83.5889%\n",
      "Epoch:  2400 | Train loss: 0.3004 | Test loss: 0.3316  | Test acc: 83.6222%\n",
      "Epoch:  2500 | Train loss: 0.2999 | Test loss: 0.3314  | Test acc: 83.6333%\n",
      "Epoch:  2600 | Train loss: 0.2994 | Test loss: 0.3313  | Test acc: 83.6778%\n",
      "Epoch:  2700 | Train loss: 0.2990 | Test loss: 0.3312  | Test acc: 83.7111%\n",
      "Epoch:  2800 | Train loss: 0.2986 | Test loss: 0.3311  | Test acc: 83.7333%\n",
      "Epoch:  2900 | Train loss: 0.2982 | Test loss: 0.3310  | Test acc: 83.7889%\n",
      "Epoch:  3000 | Train loss: 0.2979 | Test loss: 0.3309  | Test acc: 83.8000%\n",
      "Epoch:  3100 | Train loss: 0.2975 | Test loss: 0.3308  | Test acc: 83.7889%\n",
      "Epoch:  3200 | Train loss: 0.2972 | Test loss: 0.3307  | Test acc: 83.8000%\n",
      "Epoch:  3300 | Train loss: 0.2969 | Test loss: 0.3306  | Test acc: 83.8000%\n",
      "Epoch:  3400 | Train loss: 0.2966 | Test loss: 0.3305  | Test acc: 83.8111%\n",
      "Epoch:  3500 | Train loss: 0.2964 | Test loss: 0.3304  | Test acc: 83.8000%\n",
      "Epoch:  3600 | Train loss: 0.2961 | Test loss: 0.3304  | Test acc: 83.7889%\n",
      "Epoch:  3700 | Train loss: 0.2959 | Test loss: 0.3303  | Test acc: 83.8222%\n",
      "Epoch:  3800 | Train loss: 0.2957 | Test loss: 0.3302  | Test acc: 83.8444%\n",
      "Epoch:  3900 | Train loss: 0.2955 | Test loss: 0.3301  | Test acc: 83.8333%\n",
      "Epoch:  4000 | Train loss: 0.2953 | Test loss: 0.3301  | Test acc: 83.8778%\n",
      "Epoch:  4100 | Train loss: 0.2951 | Test loss: 0.3300  | Test acc: 83.8889%\n",
      "Epoch:  4200 | Train loss: 0.2949 | Test loss: 0.3299  | Test acc: 83.9333%\n",
      "Epoch:  4300 | Train loss: 0.2947 | Test loss: 0.3299  | Test acc: 83.9556%\n",
      "Epoch:  4400 | Train loss: 0.2945 | Test loss: 0.3298  | Test acc: 83.9556%\n",
      "Epoch:  4500 | Train loss: 0.2944 | Test loss: 0.3297  | Test acc: 83.9889%\n",
      "Epoch:  4600 | Train loss: 0.2942 | Test loss: 0.3297  | Test acc: 83.9778%\n",
      "Epoch:  4700 | Train loss: 0.2941 | Test loss: 0.3296  | Test acc: 84.0000%\n",
      "Epoch:  4800 | Train loss: 0.2939 | Test loss: 0.3296  | Test acc: 84.0000%\n",
      "Epoch:  4900 | Train loss: 0.2938 | Test loss: 0.3295  | Test acc: 84.0000%\n",
      "Epoch:  5000 | Train loss: 0.2936 | Test loss: 0.3294  | Test acc: 84.0000%\n",
      "Epoch:  5100 | Train loss: 0.2935 | Test loss: 0.3294  | Test acc: 84.0000%\n",
      "Epoch:  5200 | Train loss: 0.2934 | Test loss: 0.3293  | Test acc: 84.0000%\n",
      "Epoch:  5300 | Train loss: 0.2932 | Test loss: 0.3292  | Test acc: 84.0111%\n",
      "Epoch:  5400 | Train loss: 0.2931 | Test loss: 0.3292  | Test acc: 84.0333%\n",
      "Epoch:  5500 | Train loss: 0.2930 | Test loss: 0.3291  | Test acc: 84.0333%\n",
      "Epoch:  5600 | Train loss: 0.2929 | Test loss: 0.3291  | Test acc: 84.0222%\n",
      "Epoch:  5700 | Train loss: 0.2928 | Test loss: 0.3290  | Test acc: 84.0222%\n",
      "Epoch:  5800 | Train loss: 0.2927 | Test loss: 0.3289  | Test acc: 84.0222%\n",
      "Epoch:  5900 | Train loss: 0.2926 | Test loss: 0.3289  | Test acc: 84.0333%\n",
      "Epoch:  6000 | Train loss: 0.2925 | Test loss: 0.3288  | Test acc: 84.0111%\n",
      "Epoch:  6100 | Train loss: 0.2924 | Test loss: 0.3288  | Test acc: 84.0222%\n",
      "Epoch:  6200 | Train loss: 0.2923 | Test loss: 0.3287  | Test acc: 84.0333%\n",
      "Epoch:  6300 | Train loss: 0.2922 | Test loss: 0.3286  | Test acc: 84.0444%\n",
      "Epoch:  6400 | Train loss: 0.2921 | Test loss: 0.3286  | Test acc: 84.0333%\n",
      "Epoch:  6500 | Train loss: 0.2920 | Test loss: 0.3285  | Test acc: 84.0556%\n",
      "Epoch:  6600 | Train loss: 0.2919 | Test loss: 0.3285  | Test acc: 84.0556%\n",
      "Epoch:  6700 | Train loss: 0.2918 | Test loss: 0.3284  | Test acc: 84.0556%\n",
      "Epoch:  6800 | Train loss: 0.2917 | Test loss: 0.3283  | Test acc: 84.0667%\n",
      "Epoch:  6900 | Train loss: 0.2916 | Test loss: 0.3283  | Test acc: 84.0667%\n",
      "Epoch:  7000 | Train loss: 0.2915 | Test loss: 0.3282  | Test acc: 84.0667%\n",
      "Epoch:  7100 | Train loss: 0.2915 | Test loss: 0.3281  | Test acc: 84.0667%\n",
      "Epoch:  7200 | Train loss: 0.2914 | Test loss: 0.3281  | Test acc: 84.0667%\n",
      "Epoch:  7300 | Train loss: 0.2913 | Test loss: 0.3280  | Test acc: 84.0778%\n",
      "Epoch:  7400 | Train loss: 0.2912 | Test loss: 0.3280  | Test acc: 84.0778%\n",
      "Epoch:  7500 | Train loss: 0.2912 | Test loss: 0.3279  | Test acc: 84.0667%\n",
      "Epoch:  7600 | Train loss: 0.2911 | Test loss: 0.3278  | Test acc: 84.0667%\n",
      "Epoch:  7700 | Train loss: 0.2910 | Test loss: 0.3278  | Test acc: 84.0778%\n",
      "Epoch:  7800 | Train loss: 0.2910 | Test loss: 0.3277  | Test acc: 84.0778%\n",
      "Epoch:  7900 | Train loss: 0.2909 | Test loss: 0.3276  | Test acc: 84.0889%\n",
      "Epoch:  8000 | Train loss: 0.2908 | Test loss: 0.3276  | Test acc: 84.0889%\n",
      "Epoch:  8100 | Train loss: 0.2908 | Test loss: 0.3275  | Test acc: 84.1000%\n",
      "Epoch:  8200 | Train loss: 0.2907 | Test loss: 0.3275  | Test acc: 84.1111%\n",
      "Epoch:  8300 | Train loss: 0.2906 | Test loss: 0.3274  | Test acc: 84.1111%\n",
      "Epoch:  8400 | Train loss: 0.2906 | Test loss: 0.3273  | Test acc: 84.1111%\n",
      "Epoch:  8500 | Train loss: 0.2905 | Test loss: 0.3273  | Test acc: 84.1111%\n",
      "Epoch:  8600 | Train loss: 0.2904 | Test loss: 0.3272  | Test acc: 84.1222%\n",
      "Epoch:  8700 | Train loss: 0.2904 | Test loss: 0.3271  | Test acc: 84.1111%\n",
      "Epoch:  8800 | Train loss: 0.2903 | Test loss: 0.3271  | Test acc: 84.1222%\n",
      "Epoch:  8900 | Train loss: 0.2903 | Test loss: 0.3270  | Test acc: 84.1222%\n",
      "Epoch:  9000 | Train loss: 0.2902 | Test loss: 0.3270  | Test acc: 84.1333%\n",
      "Epoch:  9100 | Train loss: 0.2901 | Test loss: 0.3269  | Test acc: 84.1444%\n",
      "Epoch:  9200 | Train loss: 0.2901 | Test loss: 0.3268  | Test acc: 84.1667%\n",
      "Epoch:  9300 | Train loss: 0.2900 | Test loss: 0.3268  | Test acc: 84.1667%\n",
      "Epoch:  9400 | Train loss: 0.2900 | Test loss: 0.3267  | Test acc: 84.1778%\n",
      "Epoch:  9500 | Train loss: 0.2899 | Test loss: 0.3266  | Test acc: 84.1889%\n",
      "Epoch:  9600 | Train loss: 0.2899 | Test loss: 0.3266  | Test acc: 84.2222%\n",
      "Epoch:  9700 | Train loss: 0.2898 | Test loss: 0.3265  | Test acc: 84.2222%\n",
      "Epoch:  9800 | Train loss: 0.2898 | Test loss: 0.3265  | Test acc: 84.2556%\n",
      "Epoch:  9900 | Train loss: 0.2897 | Test loss: 0.3264  | Test acc: 84.2667%\n",
      "Epoch: 10000 | Train loss: 0.2897 | Test loss: 0.3263  | Test acc: 84.2556%\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "class Model0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(13, 20)\n",
    "        self.layer2 = nn.Linear(20, 20)\n",
    "        self.layer3 = nn.Linear(20, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # return self.layer3(self.relu(self.layer2(self.relu(self.layer1(x)))))\n",
    "        return self.layer3(self.layer2(self.layer1(x)))\n",
    "\n",
    "\n",
    "def accuracy(targets, predictions):\n",
    "    correct = torch.eq(targets, predictions).sum().item()\n",
    "    acc = correct / len(targets)\n",
    "    return acc\n",
    "\n",
    "model = Model0().to(device)\n",
    "lossFun = nn.BCEWithLogitsLoss()\n",
    "losses = torch.tensor([])\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "epochs = 10001\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    yLogits = model(XTrain).squeeze()\n",
    "    yPred = torch.round(torch.sigmoid(yLogits))\n",
    "\n",
    "    trainLoss = lossFun(yLogits, yTrain)\n",
    "    losses = torch.cat((losses, trainLoss.unsqueeze(-1).to('cpu')))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    trainLoss.backward()\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        testLogits = model(XTest).squeeze()\n",
    "        testPred = torch.round(torch.sigmoid(testLogits))\n",
    "        \n",
    "        testLoss = lossFun(testLogits, yTest)\n",
    "        testAcc = accuracy(yTest, testPred)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch:>5} | Train loss: {trainLoss:.4f} | Test loss: {testLoss:.4f}  | Test acc: {testAcc*100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6c732249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x284f9e7a150>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.scatter(np.arange(len(losses), step=1), torch.detach(losses), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d9fcb6265879064",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T23:52:37.945579Z",
     "start_time": "2024-11-20T23:52:37.941883Z"
    }
   },
   "outputs": [],
   "source": [
    "# problems\n",
    "# I didn't know how to find the data\n",
    "# getting the data from the csv was a hassle\n",
    "# had to use reciprocals to make the numbers smaller.\n",
    "# not enough epochs\n",
    "# 0.1 lr worked, but the learning rate only got up to 80. \n",
    "# I had a faulty accuracy function\n",
    "# non-linear layers did not help (relu)\n",
    "# issues with devices and converting to numpy for matplotlib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
