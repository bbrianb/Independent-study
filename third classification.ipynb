{
 "cells": [
  {
   "cell_type": "code",
   "id": "28edc5f42785b9ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T01:32:56.524047Z",
     "start_time": "2025-01-15T01:32:56.520128Z"
    }
   },
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T01:33:10.337662Z",
     "start_time": "2025-01-15T01:32:56.543992Z"
    }
   },
   "source": [
    "import csv\n",
    "import torch\n",
    "fileName = 'data/loan_data.csv'\n",
    "\n",
    "with open(fileName) as csvFile:\n",
    "    reader = csv.reader(csvFile)\n",
    "    variables = next(reader)\n",
    "    columnInfo = [[] for _ in range(len(variables))]\n",
    "    data = torch.tensor([])\n",
    "    labels = torch.tensor([])\n",
    "    for row in reader:\n",
    "        temp = torch.zeros(1, len(variables) - 1)\n",
    "        for columnIndex, column in enumerate(row[:-1]):\n",
    "            try:\n",
    "                value = float(column)\n",
    "            except ValueError:\n",
    "                if column not in columnInfo[columnIndex]:\n",
    "                    columnInfo[columnIndex].append(column)\n",
    "                value = columnInfo[columnIndex].index(column)\n",
    "            if value != 0:\n",
    "                value = value ** -1\n",
    "            temp[0][columnIndex] = value\n",
    "        data = torch.cat((data, temp))\n",
    "        labels = torch.cat((labels, torch.tensor([int(row[-1])])))\n",
    "labels = labels\n",
    "data.shape, labels.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([45000, 13]), torch.Size([45000]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "6cb129a90e9b70b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T01:33:10.364839Z",
     "start_time": "2025-01-15T01:33:10.339676Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "df = df.set_axis(variables[:-1], axis=1)\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       person_age  person_gender  person_education  person_income  \\\n",
       "0        0.045455            0.0          0.000000       0.000014   \n",
       "1        0.047619            0.0          1.000000       0.000081   \n",
       "2        0.040000            0.0          1.000000       0.000080   \n",
       "3        0.043478            0.0          0.500000       0.000013   \n",
       "4        0.041667            1.0          0.000000       0.000015   \n",
       "...           ...            ...               ...            ...   \n",
       "44995    0.037037            1.0          0.333333       0.000021   \n",
       "44996    0.027027            0.0          0.333333       0.000015   \n",
       "44997    0.030303            1.0          0.333333       0.000018   \n",
       "44998    0.034483            1.0          0.500000       0.000030   \n",
       "44999    0.041667            1.0          1.000000       0.000019   \n",
       "\n",
       "       person_emp_exp  person_home_ownership  loan_amnt  loan_intent  \\\n",
       "0            0.000000                    0.0   0.000029         0.00   \n",
       "1            0.000000                    1.0   0.001000         1.00   \n",
       "2            0.333333                    0.5   0.000182         0.50   \n",
       "3            0.000000                    0.0   0.000029         0.50   \n",
       "4            1.000000                    0.0   0.000029         0.50   \n",
       "...               ...                    ...        ...          ...   \n",
       "44995        0.166667                    0.0   0.000067         0.50   \n",
       "44996        0.058824                    0.0   0.000111         0.25   \n",
       "44997        0.142857                    0.0   0.000361         0.20   \n",
       "44998        0.250000                    0.0   0.000083         1.00   \n",
       "44999        1.000000                    0.0   0.000150         0.20   \n",
       "\n",
       "       loan_int_rate  loan_percent_income  cb_person_cred_hist_length  \\\n",
       "0           0.062422             2.040816                    0.333333   \n",
       "1           0.089767            12.500000                    0.500000   \n",
       "2           0.077700             2.272727                    0.333333   \n",
       "3           0.065660             2.272727                    0.500000   \n",
       "4           0.070077             1.886792                    0.250000   \n",
       "...              ...                  ...                         ...   \n",
       "44995       0.063857             3.225806                    0.333333   \n",
       "44996       0.071073             7.142857                    0.090909   \n",
       "44997       0.099800            20.000000                    0.100000   \n",
       "44998       0.075586             2.777778                    0.166667   \n",
       "44999       0.058651             7.692307                    0.333333   \n",
       "\n",
       "       credit_score  previous_loan_defaults_on_file  \n",
       "0          0.001783                             0.0  \n",
       "1          0.001984                             1.0  \n",
       "2          0.001575                             0.0  \n",
       "3          0.001481                             0.0  \n",
       "4          0.001706                             0.0  \n",
       "...             ...                             ...  \n",
       "44995      0.001550                             0.0  \n",
       "44996      0.001610                             0.0  \n",
       "44997      0.001497                             0.0  \n",
       "44998      0.001656                             0.0  \n",
       "44999      0.001592                             0.0  \n",
       "\n",
       "[45000 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_gender</th>\n",
       "      <th>person_education</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_exp</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>previous_loan_defaults_on_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.062422</td>\n",
       "      <td>2.040816</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.089767</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.077700</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.065660</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.070077</td>\n",
       "      <td>1.886792</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44995</th>\n",
       "      <td>0.037037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.063857</td>\n",
       "      <td>3.225806</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44996</th>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.071073</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44997</th>\n",
       "      <td>0.030303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.099800</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44998</th>\n",
       "      <td>0.034483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.075586</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44999</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.058651</td>\n",
       "      <td>7.692307</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45000 rows Ã— 13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "948933f39b0ddeb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T01:33:10.373384Z",
     "start_time": "2025-01-15T01:33:10.365823Z"
    }
   },
   "source": [
    "pct = .8\n",
    "XSplit = int(pct*len(data))\n",
    "ySplit = int(pct * len(labels))\n",
    "XTrain, XTest = data[:XSplit].to(device), data[XSplit:].to(device)\n",
    "yTrain, yTest = labels[:ySplit].to(device), labels[ySplit:].to(device)\n",
    "XTrain.shape, XTest.shape, yTrain.shape, yTest.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([36000, 13]),\n",
       " torch.Size([9000, 13]),\n",
       " torch.Size([36000]),\n",
       " torch.Size([9000]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "475ca1adbe7b3abb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T01:33:10.384890Z",
     "start_time": "2025-01-15T01:33:10.374378Z"
    }
   },
   "source": [
    "XTrain[0:5], yTrain[0:5]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4.5455e-02, 0.0000e+00, 0.0000e+00, 1.3899e-05, 0.0000e+00, 0.0000e+00,\n",
       "          2.8571e-05, 0.0000e+00, 6.2422e-02, 2.0408e+00, 3.3333e-01, 1.7825e-03,\n",
       "          0.0000e+00],\n",
       "         [4.7619e-02, 0.0000e+00, 1.0000e+00, 8.1420e-05, 0.0000e+00, 1.0000e+00,\n",
       "          1.0000e-03, 1.0000e+00, 8.9767e-02, 1.2500e+01, 5.0000e-01, 1.9841e-03,\n",
       "          1.0000e+00],\n",
       "         [4.0000e-02, 0.0000e+00, 1.0000e+00, 8.0399e-05, 3.3333e-01, 5.0000e-01,\n",
       "          1.8182e-04, 5.0000e-01, 7.7700e-02, 2.2727e+00, 3.3333e-01, 1.5748e-03,\n",
       "          0.0000e+00],\n",
       "         [4.3478e-02, 0.0000e+00, 5.0000e-01, 1.2539e-05, 0.0000e+00, 0.0000e+00,\n",
       "          2.8571e-05, 5.0000e-01, 6.5660e-02, 2.2727e+00, 5.0000e-01, 1.4815e-03,\n",
       "          0.0000e+00],\n",
       "         [4.1667e-02, 1.0000e+00, 0.0000e+00, 1.5121e-05, 1.0000e+00, 0.0000e+00,\n",
       "          2.8571e-05, 5.0000e-01, 7.0077e-02, 1.8868e+00, 2.5000e-01, 1.7065e-03,\n",
       "          0.0000e+00]], device='cuda:0'),\n",
       " tensor([1., 0., 1., 1., 1.], device='cuda:0'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "ae6a24b124633f77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T01:33:30.436737Z",
     "start_time": "2025-01-15T01:33:10.385885Z"
    }
   },
   "source": [
    "from torch import nn\n",
    "class Model0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(13, 20)\n",
    "        self.layer2 = nn.Linear(20, 20)\n",
    "        self.layer3 = nn.Linear(20, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # return self.layer3(self.relu(self.layer2(self.relu(self.layer1(x)))))\n",
    "        return self.layer3(self.layer2(self.layer1(x)))\n",
    "\n",
    "\n",
    "def accuracy(targets, predictions):\n",
    "    correct = torch.eq(targets, predictions).sum().item()\n",
    "    acc = correct / len(targets)\n",
    "    return acc\n",
    "\n",
    "model = Model0().to(device)\n",
    "lossFun = nn.BCEWithLogitsLoss()\n",
    "losses = torch.tensor([])\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "epochs = 10500\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    yLogits = model(XTrain).squeeze()\n",
    "    yPred = torch.round(torch.sigmoid(yLogits))\n",
    "\n",
    "    trainLoss = lossFun(yLogits, yTrain)\n",
    "    losses = torch.cat((losses, trainLoss.unsqueeze(-1).to('cpu')))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    trainLoss.backward()\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        testLogits = model(XTest).squeeze()\n",
    "        testPred = torch.round(torch.sigmoid(testLogits))\n",
    "        \n",
    "        testLoss = lossFun(testLogits, yTest)\n",
    "        testAcc = accuracy(yTest, testPred)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch:>5} | Train loss: {trainLoss:.4f} | Test loss: {testLoss:.4f}  | Test acc: {testAcc*100:.4f}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     0 | Train loss: 0.6355 | Test loss: 0.7310  | Test acc: 67.8667%\n",
      "Epoch:   100 | Train loss: 0.3765 | Test loss: 0.5110  | Test acc: 67.8667%\n",
      "Epoch:   200 | Train loss: 0.4015 | Test loss: 0.4090  | Test acc: 81.9444%\n",
      "Epoch:   300 | Train loss: 0.3745 | Test loss: 0.3785  | Test acc: 83.1222%\n",
      "Epoch:   400 | Train loss: 0.3569 | Test loss: 0.3639  | Test acc: 83.2222%\n",
      "Epoch:   500 | Train loss: 0.3451 | Test loss: 0.3555  | Test acc: 83.3333%\n",
      "Epoch:   600 | Train loss: 0.3368 | Test loss: 0.3501  | Test acc: 83.4333%\n",
      "Epoch:   700 | Train loss: 0.3305 | Test loss: 0.3463  | Test acc: 83.4444%\n",
      "Epoch:   800 | Train loss: 0.3256 | Test loss: 0.3435  | Test acc: 83.4889%\n",
      "Epoch:   900 | Train loss: 0.3217 | Test loss: 0.3414  | Test acc: 83.4778%\n",
      "Epoch:  1000 | Train loss: 0.3185 | Test loss: 0.3398  | Test acc: 83.4556%\n",
      "Epoch:  1100 | Train loss: 0.3159 | Test loss: 0.3385  | Test acc: 83.5222%\n",
      "Epoch:  1200 | Train loss: 0.3136 | Test loss: 0.3375  | Test acc: 83.5333%\n",
      "Epoch:  1300 | Train loss: 0.3117 | Test loss: 0.3366  | Test acc: 83.5556%\n",
      "Epoch:  1400 | Train loss: 0.3100 | Test loss: 0.3359  | Test acc: 83.5111%\n",
      "Epoch:  1500 | Train loss: 0.3085 | Test loss: 0.3354  | Test acc: 83.5000%\n",
      "Epoch:  1600 | Train loss: 0.3073 | Test loss: 0.3349  | Test acc: 83.5556%\n",
      "Epoch:  1700 | Train loss: 0.3061 | Test loss: 0.3345  | Test acc: 83.5889%\n",
      "Epoch:  1800 | Train loss: 0.3051 | Test loss: 0.3341  | Test acc: 83.6111%\n",
      "Epoch:  1900 | Train loss: 0.3042 | Test loss: 0.3338  | Test acc: 83.6333%\n",
      "Epoch:  2000 | Train loss: 0.3034 | Test loss: 0.3335  | Test acc: 83.6333%\n",
      "Epoch:  2100 | Train loss: 0.3026 | Test loss: 0.3333  | Test acc: 83.6556%\n",
      "Epoch:  2200 | Train loss: 0.3020 | Test loss: 0.3331  | Test acc: 83.6556%\n",
      "Epoch:  2300 | Train loss: 0.3014 | Test loss: 0.3329  | Test acc: 83.6333%\n",
      "Epoch:  2400 | Train loss: 0.3008 | Test loss: 0.3327  | Test acc: 83.6444%\n",
      "Epoch:  2500 | Train loss: 0.3003 | Test loss: 0.3326  | Test acc: 83.6556%\n",
      "Epoch:  2600 | Train loss: 0.2998 | Test loss: 0.3324  | Test acc: 83.6778%\n",
      "Epoch:  2700 | Train loss: 0.2993 | Test loss: 0.3323  | Test acc: 83.6778%\n",
      "Epoch:  2800 | Train loss: 0.2989 | Test loss: 0.3322  | Test acc: 83.7000%\n",
      "Epoch:  2900 | Train loss: 0.2986 | Test loss: 0.3321  | Test acc: 83.7222%\n",
      "Epoch:  3000 | Train loss: 0.2982 | Test loss: 0.3320  | Test acc: 83.7333%\n",
      "Epoch:  3100 | Train loss: 0.2979 | Test loss: 0.3319  | Test acc: 83.7333%\n",
      "Epoch:  3200 | Train loss: 0.2975 | Test loss: 0.3318  | Test acc: 83.7556%\n",
      "Epoch:  3300 | Train loss: 0.2972 | Test loss: 0.3317  | Test acc: 83.7778%\n",
      "Epoch:  3400 | Train loss: 0.2970 | Test loss: 0.3316  | Test acc: 83.8000%\n",
      "Epoch:  3500 | Train loss: 0.2967 | Test loss: 0.3316  | Test acc: 83.8000%\n",
      "Epoch:  3600 | Train loss: 0.2965 | Test loss: 0.3315  | Test acc: 83.8111%\n",
      "Epoch:  3700 | Train loss: 0.2962 | Test loss: 0.3314  | Test acc: 83.8111%\n",
      "Epoch:  3800 | Train loss: 0.2960 | Test loss: 0.3313  | Test acc: 83.8333%\n",
      "Epoch:  3900 | Train loss: 0.2958 | Test loss: 0.3313  | Test acc: 83.8222%\n",
      "Epoch:  4000 | Train loss: 0.2956 | Test loss: 0.3312  | Test acc: 83.8333%\n",
      "Epoch:  4100 | Train loss: 0.2954 | Test loss: 0.3311  | Test acc: 83.8778%\n",
      "Epoch:  4200 | Train loss: 0.2952 | Test loss: 0.3311  | Test acc: 83.9000%\n",
      "Epoch:  4300 | Train loss: 0.2950 | Test loss: 0.3310  | Test acc: 83.9000%\n",
      "Epoch:  4400 | Train loss: 0.2948 | Test loss: 0.3309  | Test acc: 83.8889%\n",
      "Epoch:  4500 | Train loss: 0.2947 | Test loss: 0.3309  | Test acc: 83.9111%\n",
      "Epoch:  4600 | Train loss: 0.2945 | Test loss: 0.3308  | Test acc: 83.9111%\n",
      "Epoch:  4700 | Train loss: 0.2944 | Test loss: 0.3307  | Test acc: 83.9111%\n",
      "Epoch:  4800 | Train loss: 0.2942 | Test loss: 0.3307  | Test acc: 83.9222%\n",
      "Epoch:  4900 | Train loss: 0.2941 | Test loss: 0.3306  | Test acc: 83.9333%\n",
      "Epoch:  5000 | Train loss: 0.2939 | Test loss: 0.3305  | Test acc: 83.9444%\n",
      "Epoch:  5100 | Train loss: 0.2938 | Test loss: 0.3305  | Test acc: 83.9556%\n",
      "Epoch:  5200 | Train loss: 0.2937 | Test loss: 0.3304  | Test acc: 83.9667%\n",
      "Epoch:  5300 | Train loss: 0.2935 | Test loss: 0.3304  | Test acc: 83.9778%\n",
      "Epoch:  5400 | Train loss: 0.2934 | Test loss: 0.3303  | Test acc: 83.9889%\n",
      "Epoch:  5500 | Train loss: 0.2933 | Test loss: 0.3302  | Test acc: 83.9778%\n",
      "Epoch:  5600 | Train loss: 0.2932 | Test loss: 0.3302  | Test acc: 83.9667%\n",
      "Epoch:  5700 | Train loss: 0.2931 | Test loss: 0.3301  | Test acc: 83.9778%\n",
      "Epoch:  5800 | Train loss: 0.2930 | Test loss: 0.3300  | Test acc: 83.9667%\n",
      "Epoch:  5900 | Train loss: 0.2929 | Test loss: 0.3300  | Test acc: 83.9667%\n",
      "Epoch:  6000 | Train loss: 0.2928 | Test loss: 0.3299  | Test acc: 83.9778%\n",
      "Epoch:  6100 | Train loss: 0.2927 | Test loss: 0.3298  | Test acc: 83.9778%\n",
      "Epoch:  6200 | Train loss: 0.2926 | Test loss: 0.3298  | Test acc: 83.9667%\n",
      "Epoch:  6300 | Train loss: 0.2925 | Test loss: 0.3297  | Test acc: 83.9556%\n",
      "Epoch:  6400 | Train loss: 0.2924 | Test loss: 0.3296  | Test acc: 83.9556%\n",
      "Epoch:  6500 | Train loss: 0.2923 | Test loss: 0.3296  | Test acc: 83.9667%\n",
      "Epoch:  6600 | Train loss: 0.2922 | Test loss: 0.3295  | Test acc: 83.9889%\n",
      "Epoch:  6700 | Train loss: 0.2921 | Test loss: 0.3295  | Test acc: 83.9889%\n",
      "Epoch:  6800 | Train loss: 0.2920 | Test loss: 0.3294  | Test acc: 83.9889%\n",
      "Epoch:  6900 | Train loss: 0.2920 | Test loss: 0.3293  | Test acc: 84.0000%\n",
      "Epoch:  7000 | Train loss: 0.2919 | Test loss: 0.3293  | Test acc: 84.0111%\n",
      "Epoch:  7100 | Train loss: 0.2918 | Test loss: 0.3292  | Test acc: 84.0556%\n",
      "Epoch:  7200 | Train loss: 0.2917 | Test loss: 0.3291  | Test acc: 84.0556%\n",
      "Epoch:  7300 | Train loss: 0.2916 | Test loss: 0.3291  | Test acc: 84.0667%\n",
      "Epoch:  7400 | Train loss: 0.2916 | Test loss: 0.3290  | Test acc: 84.0778%\n",
      "Epoch:  7500 | Train loss: 0.2915 | Test loss: 0.3289  | Test acc: 84.0889%\n",
      "Epoch:  7600 | Train loss: 0.2914 | Test loss: 0.3289  | Test acc: 84.1000%\n",
      "Epoch:  7700 | Train loss: 0.2914 | Test loss: 0.3288  | Test acc: 84.1111%\n",
      "Epoch:  7800 | Train loss: 0.2913 | Test loss: 0.3287  | Test acc: 84.1333%\n",
      "Epoch:  7900 | Train loss: 0.2912 | Test loss: 0.3287  | Test acc: 84.1444%\n",
      "Epoch:  8000 | Train loss: 0.2912 | Test loss: 0.3286  | Test acc: 84.1444%\n",
      "Epoch:  8100 | Train loss: 0.2911 | Test loss: 0.3286  | Test acc: 84.1444%\n",
      "Epoch:  8200 | Train loss: 0.2910 | Test loss: 0.3285  | Test acc: 84.1222%\n",
      "Epoch:  8300 | Train loss: 0.2910 | Test loss: 0.3284  | Test acc: 84.1222%\n",
      "Epoch:  8400 | Train loss: 0.2909 | Test loss: 0.3284  | Test acc: 84.1222%\n",
      "Epoch:  8500 | Train loss: 0.2908 | Test loss: 0.3283  | Test acc: 84.1222%\n",
      "Epoch:  8600 | Train loss: 0.2908 | Test loss: 0.3282  | Test acc: 84.1222%\n",
      "Epoch:  8700 | Train loss: 0.2907 | Test loss: 0.3282  | Test acc: 84.1222%\n",
      "Epoch:  8800 | Train loss: 0.2906 | Test loss: 0.3281  | Test acc: 84.1222%\n",
      "Epoch:  8900 | Train loss: 0.2906 | Test loss: 0.3280  | Test acc: 84.1222%\n",
      "Epoch:  9000 | Train loss: 0.2905 | Test loss: 0.3280  | Test acc: 84.1222%\n",
      "Epoch:  9100 | Train loss: 0.2905 | Test loss: 0.3279  | Test acc: 84.1333%\n",
      "Epoch:  9200 | Train loss: 0.2904 | Test loss: 0.3278  | Test acc: 84.1333%\n",
      "Epoch:  9300 | Train loss: 0.2904 | Test loss: 0.3278  | Test acc: 84.1333%\n",
      "Epoch:  9400 | Train loss: 0.2903 | Test loss: 0.3277  | Test acc: 84.1333%\n",
      "Epoch:  9500 | Train loss: 0.2903 | Test loss: 0.3276  | Test acc: 84.1333%\n",
      "Epoch:  9600 | Train loss: 0.2902 | Test loss: 0.3276  | Test acc: 84.1444%\n",
      "Epoch:  9700 | Train loss: 0.2902 | Test loss: 0.3275  | Test acc: 84.1444%\n",
      "Epoch:  9800 | Train loss: 0.2901 | Test loss: 0.3275  | Test acc: 84.1444%\n",
      "Epoch:  9900 | Train loss: 0.2900 | Test loss: 0.3274  | Test acc: 84.1444%\n",
      "Epoch: 10000 | Train loss: 0.2900 | Test loss: 0.3273  | Test acc: 84.1556%\n",
      "Epoch: 10100 | Train loss: 0.2899 | Test loss: 0.3273  | Test acc: 84.1667%\n",
      "Epoch: 10200 | Train loss: 0.2899 | Test loss: 0.3272  | Test acc: 84.1778%\n",
      "Epoch: 10300 | Train loss: 0.2898 | Test loss: 0.3271  | Test acc: 84.1889%\n",
      "Epoch: 10400 | Train loss: 0.2898 | Test loss: 0.3271  | Test acc: 84.1889%\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "6c732249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T01:33:30.604074Z",
     "start_time": "2025-01-15T01:33:30.437724Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.scatter(np.arange(len(losses), step=1), torch.detach(losses), 1)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x155bf1410a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGeCAYAAABGlgGHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqSUlEQVR4nO3dfXTU1Z3H8U8eJ0khiRozgTSCIBURJJiYELFb9pg2qxzQbk83pTxtttKVokXjakl5WrQStnY5qYik5UDtKa1QutRaQVhOkHbRAGsABcEooiSNTIDVZDBCApm7f6BjJk/MhExuknm/zvkdk9/c38x3Lgfm4/3deyfMGGMEAABgSbjtAgAAQGgjjAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsirRdgD88Ho8+/PBDDRw4UGFhYbbLAQAAfjDG6OzZsxo8eLDCwzsZ/zBd8Mwzz5ghQ4YYh8NhsrKyzN69ezts29TUZJYuXWqGDRtmHA6HueWWW8zLL78c0OtVV1cbSRwcHBwcHBx98Kiuru70cz7gkZGNGzeqsLBQpaWlys7OVklJifLy8lRZWank5OQ27RcuXKj169drzZo1GjlypLZv365vfvObeu211zRu3Di/XnPgwIGSpOrqasXHxwdaMgAAsMDtdistLc37Od6RMGMC+6K87Oxs3XbbbXrmmWckXbqFkpaWpgcffFDz589v037w4MFasGCB5s6d6z33rW99S7GxsVq/fr1fr+l2u5WQkKD6+nrCCAAAfYS/n98BTWBtampSRUWFcnNzv3iC8HDl5uaqvLy83WsaGxsVExPjcy42Nla7d+/u8HUaGxvldrt9DgAA0D8FFEbOnDmj5uZmOZ1On/NOp1Mul6vda/Ly8rRixQq9++678ng82rFjhzZv3qyTJ092+DrFxcVKSEjwHmlpaYGUCQAA+pCgL+39+c9/rhEjRmjkyJGKjo7WAw88oIKCgk5n1RYVFam+vt57VFdXB7tMAABgSUBhJCkpSREREaqtrfU5X1tbq5SUlHavufbaa/XCCy+ooaFBJ06c0Ntvv60BAwZo2LBhHb6Ow+FQfHy8zwEAAPqngMJIdHS0MjIyVFZW5j3n8XhUVlamnJycTq+NiYlRamqqLl68qP/6r//SPffc07WKAQBAvxLw0t7CwkLNmjVLmZmZysrKUklJiRoaGlRQUCBJmjlzplJTU1VcXCxJ2rt3r2pqapSenq6amhr9+7//uzwejx577LHufScAAKBPCjiM5Ofn6/Tp01q8eLFcLpfS09O1bds276TWqqoqn/kg58+f18KFC3X8+HENGDBAd999t37zm98oMTGx294EAADouwLeZ8QG9hkBAKDvCco+IwAAAN2NMAIAAKwijAAAAKsIIwAAwCrCSCvr95zQhOU7tX7PCdulAAAQEggjraze9Z5q6s5p9a73bJcCAEBIIIy0MmficKUmxmrOxOG2SwEAICSwzwgAAAgK9hkBAAB9AmEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABY1aUwsmrVKg0dOlQxMTHKzs7Wvn37Om1fUlKiG2+8UbGxsUpLS9PDDz+s8+fPd6lgAADQvwQcRjZu3KjCwkItWbJE+/fv19ixY5WXl6dTp0612/53v/ud5s+fryVLlujo0aNau3atNm7cqB//+MdXXDwAAOj7Ag4jK1as0OzZs1VQUKBRo0aptLRUcXFxWrduXbvtX3vtNU2YMEHf/e53NXToUH3jG9/Q1KlTLzuaAgAAQkNAYaSpqUkVFRXKzc394gnCw5Wbm6vy8vJ2r7n99ttVUVHhDR/Hjx/X1q1bdffdd3f4Oo2NjXK73T4HAADonyIDaXzmzBk1NzfL6XT6nHc6nXr77bfbvea73/2uzpw5ozvuuEPGGF28eFH3339/p7dpiouLtXTp0kBKAwAAfVTQV9Ps2rVLy5Yt07PPPqv9+/dr8+bN2rJli5544okOrykqKlJ9fb33qK6uDnaZAADAkoBGRpKSkhQREaHa2lqf87W1tUpJSWn3mkWLFmnGjBm67777JEljxoxRQ0ODvv/972vBggUKD2+bhxwOhxwORyClAQCAPiqgkZHo6GhlZGSorKzMe87j8aisrEw5OTntXvPpp5+2CRwRERGSJGNMoPUCAIB+JqCREUkqLCzUrFmzlJmZqaysLJWUlKihoUEFBQWSpJkzZyo1NVXFxcWSpMmTJ2vFihUaN26csrOzdezYMS1atEiTJ0/2hhIAABC6Ag4j+fn5On36tBYvXiyXy6X09HRt27bNO6m1qqrKZyRk4cKFCgsL08KFC1VTU6Nrr71WkydP1pNPPtl97wIAAPRZYaYP3Ctxu91KSEhQfX294uPjbZcDAAD84O/nN99NAwAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKu6FEZWrVqloUOHKiYmRtnZ2dq3b1+HbSdOnKiwsLA2x6RJk7pcNAAA6D8CDiMbN25UYWGhlixZov3792vs2LHKy8vTqVOn2m2/efNmnTx50nscPnxYERER+va3v33FxQMAgL4v4DCyYsUKzZ49WwUFBRo1apRKS0sVFxendevWtdv+6quvVkpKivfYsWOH4uLiCCMAAEBSgGGkqalJFRUVys3N/eIJwsOVm5ur8vJyv55j7dq1+s53vqMvfelLHbZpbGyU2+32OQAAQP8UUBg5c+aMmpub5XQ6fc47nU65XK7LXr9v3z4dPnxY9913X6ftiouLlZCQ4D3S0tICKRMAAPQhPbqaZu3atRozZoyysrI6bVdUVKT6+nrvUV1d3UMVAgCAnhYZSOOkpCRFRESotrbW53xtba1SUlI6vbahoUEbNmzQ448/ftnXcTgccjgcgZQGAAD6qIBGRqKjo5WRkaGysjLvOY/Ho7KyMuXk5HR67aZNm9TY2Kjp06d3rVIAANAvBTQyIkmFhYWaNWuWMjMzlZWVpZKSEjU0NKigoECSNHPmTKWmpqq4uNjnurVr1+ree+/VNddc0z2VAwCAfiHgMJKfn6/Tp09r8eLFcrlcSk9P17Zt27yTWquqqhQe7jvgUllZqd27d+u///u/u6dqAADQb4QZY4ztIi7H7XYrISFB9fX1io+Pt10OAADwg7+f33w3DQAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwKqTDyPo9JzRh+U6t33PCdikAAISskA4jq3e9p5q6c1q96z3bpQAAELJCOozMmThcqYmxmjNxuO1SAAAIWWHGGGO7iMtxu91KSEhQfX294uPjbZcDAAD84O/nd0iPjAAAAPsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKu6FEZWrVqloUOHKiYmRtnZ2dq3b1+n7evq6jR37lwNGjRIDodDX/nKV7R169YuFQwAAPqXyEAv2LhxowoLC1VaWqrs7GyVlJQoLy9PlZWVSk5ObtO+qalJX//615WcnKw//OEPSk1N1YkTJ5SYmNgd9QMAgD4uzBhjArkgOztbt912m5555hlJksfjUVpamh588EHNnz+/TfvS0lI99dRTevvttxUVFdWlIt1utxISElRfX6/4+PguPQcAAOhZ/n5+B3SbpqmpSRUVFcrNzf3iCcLDlZubq/Ly8navefHFF5WTk6O5c+fK6XRq9OjRWrZsmZqbmzt8ncbGRrndbp8DAAD0TwGFkTNnzqi5uVlOp9PnvNPplMvlavea48eP6w9/+IOam5u1detWLVq0SP/5n/+pn/zkJx2+TnFxsRISErxHWlpaIGUCAIA+JOiraTwej5KTk/XLX/5SGRkZys/P14IFC1RaWtrhNUVFRaqvr/ce1dXVwS4TAABYEtAE1qSkJEVERKi2ttbnfG1trVJSUtq9ZtCgQYqKilJERIT33E033SSXy6WmpiZFR0e3ucbhcMjhcARSGgAA6KMCGhmJjo5WRkaGysrKvOc8Ho/KysqUk5PT7jUTJkzQsWPH5PF4vOfeeecdDRo0qN0gAgAAQkvAt2kKCwu1Zs0a/frXv9bRo0c1Z84cNTQ0qKCgQJI0c+ZMFRUVedvPmTNHH330kebNm6d33nlHW7Zs0bJlyzR37tzuexcAAKDPCnifkfz8fJ0+fVqLFy+Wy+VSenq6tm3b5p3UWlVVpfDwLzJOWlqatm/frocffli33HKLUlNTNW/ePP3oRz/qvncBAAD6rID3GbGBfUYAAOh7grLPCAAAQHcjjAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMNLK+j0nNGH5Tq3fc8J2KQAAhATCSCurd72nmrpzWr3rPdulAAAQEggjrcyZOFypibGaM3G47VIAAAgJYcYYY7uIy3G73UpISFB9fb3i4+NtlwMAAPzg7+c3IyMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALAqpMPI+j0nNGH5Tq3fc8J2KQAAhKyQDiOrd72nmrpzWr3rPdulAAAQskI6jMyZOFypibGaM3G47VIAAAhZYcYYY7uIy3G73UpISFB9fb3i4+NtlwMAAPzg7+d3l0ZGVq1apaFDhyomJkbZ2dnat29fh22fe+45hYWF+RwxMTFdeVkAANAPBRxGNm7cqMLCQi1ZskT79+/X2LFjlZeXp1OnTnV4TXx8vE6ePOk9TpxgwigAALgk4DCyYsUKzZ49WwUFBRo1apRKS0sVFxendevWdXhNWFiYUlJSvIfT6byiogEAQP8RUBhpampSRUWFcnNzv3iC8HDl5uaqvLy8w+s++eQTDRkyRGlpabrnnnv01ltvdfo6jY2NcrvdPgcAAOifAgojZ86cUXNzc5uRDafTKZfL1e41N954o9atW6c//elPWr9+vTwej26//Xb97W9/6/B1iouLlZCQ4D3S0tICKRMAAPQhQV/am5OTo5kzZyo9PV1f+9rXtHnzZl177bX6xS9+0eE1RUVFqq+v9x7V1dXBLtOLjdAAAOhZAYWRpKQkRUREqLa21ud8bW2tUlJS/HqOqKgojRs3TseOHeuwjcPhUHx8vM/RU9gIDQCAnhVQGImOjlZGRobKysq85zwej8rKypSTk+PXczQ3N+vQoUMaNGhQYJX2EDZCAwCgZ0UGekFhYaFmzZqlzMxMZWVlqaSkRA0NDSooKJAkzZw5U6mpqSouLpYkPf744xo/frxuuOEG1dXV6amnntKJEyd03333de876SbTxw/R9PFDbJcBAEDICDiM5Ofn6/Tp01q8eLFcLpfS09O1bds276TWqqoqhYd/MeDy8ccfa/bs2XK5XLrqqquUkZGh1157TaNGjeq+dwEAAPostoMHAABBEdTt4AEAALoLYQQAAFgV0mGEPUUAALAvpMMIe4oAAGBfSIcR9hQBAMA+VtMAAICgYDWNH5gzAgCAfSEdRp7cckQ1def05JYjtksBACBkhXQYOX/BI0k6d8GjKSt3W64GAIDQFNJhZPLYwd6f36ypt1gJAAChK6TDyNNTx9kuAQCAkBfSYQQAANhHGAEAAFYRRgAAgFWEkVbYewQAgJ5FGGmF76sBAKBnEUZa4ftqAADoWZG2C+htpo8founjh9guAwCAkMHISAs/fP6A7RIAAAg5IR9GprTYhfXFNz60WAkAAKEp5MMIu7ACAGBXyIcRAABgF2GkFfYZAQCgZxFGWmGfEQAAehZhpJWMIVcpIuzSfwEAQPARRlqpOPGxms2l/wIAgOAjjLTCDqwAAPQsdmBthR1YAQDoWYyMtMJqGgAAehZhpJWfba9kNQ0AAD2IMCIpNirC+3ND40VW0wAA0IMII5IWTLrJ+/MFj1GzufQ9NdyqAQAg+AgjUocTVn+2vbKHKwEAIPQQRjrR0HjRdgkAAPR7hJHPhIf5/le6dMsGAAAEF2HkM5/nDvIHAAA9izACAACsIox8pr3bNJJYUQMAQJARRj7T0W2aJ7cc6fliAAAIIYSRz7QcGZkydrD3/LkLHksVAQAQGggjn2k5MvL01HF2iwEAIIQQRj7T0ZwRAAAQXISRz7QcGZmwfKfPY0xiBQAgeAgjn2k5IlJTd87nsaUvvtXD1QAAEDoII59pvYomNuqLrmEnVgAAgocw8pnYqAifnxdMGmWxGgAAQkeXwsiqVas0dOhQxcTEKDs7W/v27fPrug0bNigsLEz33ntvV142qBZMusn78/kLzW2+yZd5IwAABEfAYWTjxo0qLCzUkiVLtH//fo0dO1Z5eXk6depUp9d98MEH+rd/+zd99atf7XKxwTR9/BBFfTZxxKht+GDeCAAAwRFwGFmxYoVmz56tgoICjRo1SqWlpYqLi9O6des6vKa5uVnTpk3T0qVLNWzYsCsquKes3vWez+ZnzBsBACA4AgojTU1NqqioUG5u7hdPEB6u3NxclZeXd3jd448/ruTkZH3ve9/z63UaGxvldrt9jp7QMnDMmTiczc8AAOgBAYWRM2fOqLm5WU6n0+e80+mUy+Vq95rdu3dr7dq1WrNmjd+vU1xcrISEBO+RlpYWSJld1nJ57773P+qR1wQAINQFdTXN2bNnNWPGDK1Zs0ZJSUl+X1dUVKT6+nrvUV1dHcQqv9DyTsyf3/iwzeNTVu7ukToAAAglkYE0TkpKUkREhGpra33O19bWKiUlpU379957Tx988IEmT57sPefxXPriucjISFVWVmr48OFtrnM4HHI4HIGU1i2iwsO8t2rCPhsluSU1QW/W1EuS978AAKD7BDQyEh0drYyMDJWVlXnPeTwelZWVKScnp037kSNH6tChQzp48KD3mDJliv7+7/9eBw8e7LHbL13hMZdW1Lz44B22SwEAoF8LaGREkgoLCzVr1ixlZmYqKytLJSUlamhoUEFBgSRp5syZSk1NVXFxsWJiYjR69Gif6xMTEyWpzfneoPWKmZ9tr2yz3wgAAOheAYeR/Px8nT59WosXL5bL5VJ6erq2bdvmndRaVVWl8PC+ubFry9s0ktTQeLFNmykrdzNaAgBANwozxvT6DTTcbrcSEhJUX1+v+Pj4oL3OiB9vbTM68sHySZqycrfPfJEPlk8KWg0AAPQX/n5+980hjCDpaGMzRkIAAAgewkgLUS03GpHvviMt/fD5Az1QDQAAoYEw0omWAyURLYLJi+3sQQIAALqGMNJCe7dpPv/CvKX39L7VPwAA9AeEkRZa36aRpCe3HJGkNkt8W3+rLwAA6BrCSAtfcrRd6Xzugqfdtov/dDjY5QAAEBIIIy38W96NnT5+S2qC9+cOFt4AAIAAEUZamD5+iKaMHewzWbWl1kt8uVUDAMCVI4y08vTUcXqv2HdTs45CB7dqAAC4coSRDsRGRXh/XvriW96fuVUDAED3Iox0YMGkm7w/t1zy2/pWzZSVu3usJgAA+iPCSAc6+7bellNKWn5nDQAACBxhpAueuNd3AzQmsgIA0HWEET+1vB3TetRk4QtMZAUAoKsII51oOVm19e2Y1MQYn98ZHQEAoGsII51oPVm1pVfn3+nzO6MjAAB0DWEkAK1HPxgdAQDgyhFGAtB6kzNGRwAAuHKEkcuYMnaw9+f2NjlLjPX9cj32HQEAIDCEkct4euo4n99b34o5uCTP53f2HQEAIDCEkQC19300reeO3LTo5Z4qBwCAPo8w4ofLfR9N67kj5y549MPnDwS7LAAA+gXCiB9aL/FtL2j8pNWurC++8WFQawIAoL8gjHRBe0Fj+vghio3y7c5hRVt6qiQAAPoswoifWt6qkdofHTn6xF0+v3sM80cAALgcwoifWt+q6eg2TOvbNecueJS+dHvQ6gIAoK8jjASg9aqZ9kZHpo8f0mYUpe7cRU1YXhbU2gAA6KsIIwFovWqmo9GRFx+8o838kZq68wQSAADaQRgJUOvRkY4CxtEn7lJUeJjPuZq689yyAQCgFcJIgFqPjtTUne/wC/LeXXZ3m0BSd+4ik1oBAGiBMNIFreeEdPYFee8uu1ut8ojOXfBo6HyW/QIAIBFGuuTFB+9oM+LR2Z4ix4sntWkvSUPnb2GnVgBAyCOMdNG7y+72+f1ye4q8u+zuNt/wK12aBDvix1u7vT4AAPoKwsgVmDJ2sM/v5y54Og0WB5fktblGki54jIbO36IpK3d3e40AAPR2hJEr8PTUcW1W11zwmE4DydNTx+mD5ZPafezNmnrmkgAAQg5h5Aq9Ov/ONrdfLniMrr9MqPhg+aR2b9tIl+aSEEoAAKEizBhjbBdxOW63WwkJCaqvr1d8fLztctqVvnS76s5dbHN+ytjBenrquE6vvX7+FnX2h9DRSAoAAL2Zv5/fhJFu1FEgCZP0/mUCxfo9JzpdIixdWlLc+jtyAADorQgjlvzw+QMdbhOfGBupg0vyunx9S4yWAAB6O8KIZZ3devEnlEjya95IeNilfUwAAOhtCCO9wJSVu/VmTX2Hj/sbJIYVbZHHzz8lRkwAAL0FYaQXuWnRyzp3wdNpG3/mg/gzr6QlRk0AADYRRnqhET/eqgt+DHH4E0wuN+rSEUZOAAA9hTDSi01YXqaauvN+t/cnQHR1XxJ/VvoAANAVhJE+4nJ7jLTnJ/eO1vTxQzp8PNCw057YqHAdfeKuK3oOAEBoI4z0QV0JJp/rLKAEOtfkcvxdDQQACG1BDSOrVq3SU089JZfLpbFjx2rlypXKyspqt+3mzZu1bNkyHTt2TBcuXNCIESP0yCOPaMaMGd3+ZvoTf/cbuZyOgkNX55z4g1s/AAApiGFk48aNmjlzpkpLS5Wdna2SkhJt2rRJlZWVSk5ObtN+165d+vjjjzVy5EhFR0frpZde0iOPPKItW7YoL8+//7sOxTDSnmB8X03r7er9WfnTnS53ywkA0HcFLYxkZ2frtttu0zPPPCNJ8ng8SktL04MPPqj58+f79Ry33nqrJk2apCeeeMKv9oSRjvXUF+pNGTtYLx866ddqoGBjPgsA9A3+fn63/7WxHWhqalJFRYWKioq858LDw5Wbm6vy8vLLXm+M0c6dO1VZWan/+I//6LBdY2OjGhsbvb+73e5AygwpHa208XcZsb+645ZRdzl3wdMtISw1MUavzr+zGyoCAFyJgMLImTNn1NzcLKfT6XPe6XTq7bff7vC6+vp6paamqrGxUREREXr22Wf19a9/vcP2xcXFWrp0aSCloZV3l93d6eNXMlm2v6ipOx/0kSX2dQGAywsojHTVwIEDdfDgQX3yyScqKytTYWGhhg0bpokTJ7bbvqioSIWFhd7f3W630tLSeqLUkOHvBNOeug3UX/Wm/mNHXgC9VUBhJCkpSREREaqtrfU5X1tbq5SUlA6vCw8P1w033CBJSk9P19GjR1VcXNxhGHE4HHI4HIGUhiDpyv/Zd/ctInQPj+ld4ag7MQIF9G0BhZHo6GhlZGSorKxM9957r6RLE1jLysr0wAMP+P08Ho/HZ04I+pfL3SLyV/rS7ao7d7Fbngv9W38NWTYR8NCTAr5NU1hYqFmzZikzM1NZWVkqKSlRQ0ODCgoKJEkzZ85UamqqiouLJV2a/5GZmanhw4ersbFRW7du1W9+8xutXr26e98J+p2e2litp5czA30BAS/02LyVG3AYyc/P1+nTp7V48WK5XC6lp6dr27Zt3kmtVVVVCg8P97ZvaGjQD37wA/3tb39TbGysRo4cqfXr1ys/P7/73gVwBXrzMmFueQHoKTb/qWE7eAC9BuELsKu7b88FZZ8RAAim7ppvBP8wLwsthYfZe23CCACEKL7wEr1F+OWbAAAABA9hBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYFWf+NZeY4wkye12W64EAAD46/PP7c8/xzvSJ8LI2bNnJUlpaWmWKwEAAIE6e/asEhISOnw8zFwurvQCHo9HH374oQYOHKiwsLBue1632620tDRVV1crPj6+25431NGvwUG/Bgf9Ghz0a3D0tX41xujs2bMaPHiwwsM7nhnSJ0ZGwsPD9eUvfzlozx8fH98n/lD7Gvo1OOjX4KBfg4N+DY6+1K+djYh8jgmsAADAKsIIAACwKqTDiMPh0JIlS+RwOGyX0q/Qr8FBvwYH/Roc9Gtw9Nd+7RMTWAEAQP8V0iMjAADAPsIIAACwijACAACsIowAAACrCCMAAMCqkA4jq1at0tChQxUTE6Ps7Gzt27fPdkm9RnFxsW677TYNHDhQycnJuvfee1VZWenT5vz585o7d66uueYaDRgwQN/61rdUW1vr06aqqkqTJk1SXFyckpOT9eijj+rixYs+bXbt2qVbb71VDodDN9xwg5577rlgv71eYfny5QoLC9NDDz3kPUefdk1NTY2mT5+ua665RrGxsRozZoxef/117+PGGC1evFiDBg1SbGyscnNz9e677/o8x0cffaRp06YpPj5eiYmJ+t73vqdPPvnEp82bb76pr371q4qJiVFaWpp++tOf9sj7s6G5uVmLFi3S9ddfr9jYWA0fPlxPPPGEzxee0a+X99e//lWTJ0/W4MGDFRYWphdeeMHn8Z7sw02bNmnkyJGKiYnRmDFjtHXr1m5/v11mQtSGDRtMdHS0WbdunXnrrbfM7NmzTWJioqmtrbVdWq+Ql5dnfvWrX5nDhw+bgwcPmrvvvttcd9115pNPPvG2uf/++01aWpopKyszr7/+uhk/fry5/fbbvY9fvHjRjB492uTm5poDBw6YrVu3mqSkJFNUVORtc/z4cRMXF2cKCwvNkSNHzMqVK01ERITZtm1bj77fnrZv3z4zdOhQc8stt5h58+Z5z9Ongfvoo4/MkCFDzD//8z+bvXv3muPHj5vt27ebY8eOedssX77cJCQkmBdeeMG88cYbZsqUKeb66683586d87b5h3/4BzN27FizZ88e8z//8z/mhhtuMFOnTvU+Xl9fb5xOp5k2bZo5fPiwef75501sbKz5xS9+0aPvt6c8+eST5pprrjEvvfSSef/9982mTZvMgAEDzM9//nNvG/r18rZu3WoWLFhgNm/ebCSZP/7xjz6P91QfvvrqqyYiIsL89Kc/NUeOHDELFy40UVFR5tChQ0HvA3+EbBjJysoyc+fO9f7e3NxsBg8ebIqLiy1W1XudOnXKSDJ/+ctfjDHG1NXVmaioKLNp0yZvm6NHjxpJpry83Bhz6S9heHi4cblc3jarV6828fHxprGx0RhjzGOPPWZuvvlmn9fKz883eXl5wX5L1pw9e9aMGDHC7Nixw3zta1/zhhH6tGt+9KMfmTvuuKPDxz0ej0lJSTFPPfWU91xdXZ1xOBzm+eefN8YYc+TIESPJ/O///q+3zcsvv2zCwsJMTU2NMcaYZ5991lx11VXefv78tW+88cbufku9wqRJk8y//Mu/+Jz7x3/8RzNt2jRjDP3aFa3DSE/24T/90z+ZSZMm+dSTnZ1t/vVf/7Vb32NXheRtmqamJlVUVCg3N9d7Ljw8XLm5uSovL7dYWe9VX18vSbr66qslSRUVFbpw4YJPH44cOVLXXXedtw/Ly8s1ZswYOZ1Ob5u8vDy53W699dZb3jYtn+PzNv35z2Hu3LmaNGlSm/dNn3bNiy++qMzMTH37299WcnKyxo0bpzVr1ngff//99+VyuXz6JCEhQdnZ2T79mpiYqMzMTG+b3NxchYeHa+/evd42f/d3f6fo6Ghvm7y8PFVWVurjjz8O9tvscbfffrvKysr0zjvvSJLeeOMN7d69W3fddZck+rU79GQf9vZ/F0IyjJw5c0bNzc0+/6BLktPplMvlslRV7+XxePTQQw9pwoQJGj16tCTJ5XIpOjpaiYmJPm1b9qHL5Wq3jz9/rLM2brdb586dC8bbsWrDhg3av3+/iouL2zxGn3bN8ePHtXr1ao0YMULbt2/XnDlz9MMf/lC//vWvJX3RL539fXe5XEpOTvZ5PDIyUldffXVAfd+fzJ8/X9/5znc0cuRIRUVFady4cXrooYc0bdo0SfRrd+jJPuyoTW/p40jbBaD3mzt3rg4fPqzdu3fbLqVPq66u1rx587Rjxw7FxMTYLqff8Hg8yszM1LJlyyRJ48aN0+HDh1VaWqpZs2ZZrq7v+v3vf6/f/va3+t3vfqebb75ZBw8e1EMPPaTBgwfTr+h2ITkykpSUpIiIiDarFGpra5WSkmKpqt7pgQce0EsvvaRXXnlFX/7yl73nU1JS1NTUpLq6Op/2LfswJSWl3T7+/LHO2sTHxys2Nra7345VFRUVOnXqlG699VZFRkYqMjJSf/nLX/T0008rMjJSTqeTPu2CQYMGadSoUT7nbrrpJlVVVUn6ol86+/uekpKiU6dO+Tx+8eJFffTRRwH1fX/y6KOPekdHxowZoxkzZujhhx/2jurRr1euJ/uwoza9pY9DMoxER0crIyNDZWVl3nMej0dlZWXKycmxWFnvYYzRAw88oD/+8Y/auXOnrr/+ep/HMzIyFBUV5dOHlZWVqqqq8vZhTk6ODh065PMXaceOHYqPj/d+eOTk5Pg8x+dt+uOfw5133qlDhw7p4MGD3iMzM1PTpk3z/kyfBm7ChAltlp2/8847GjJkiCTp+uuvV0pKik+fuN1u7d2716df6+rqVFFR4W2zc+dOeTweZWdne9v89a9/1YULF7xtduzYoRtvvFFXXXVV0N6fLZ9++qnCw30/IiIiIuTxeCTRr92hJ/uw1/+7YHsGrS0bNmwwDofDPPfcc+bIkSPm+9//vklMTPRZpRDK5syZYxISEsyuXbvMyZMnvcenn37qbXP//feb6667zuzcudO8/vrrJicnx+Tk5Hgf/3wZ6je+8Q1z8OBBs23bNnPttde2uwz10UcfNUePHjWrVq3q18tQW2u5msYY+rQr9u3bZyIjI82TTz5p3n33XfPb3/7WxMXFmfXr13vbLF++3CQmJpo//elP5s033zT33HNPu8snx40bZ/bu3Wt2795tRowY4bN8sq6uzjidTjNjxgxz+PBhs2HDBhMXF9dvlqC2NmvWLJOamupd2rt582aTlJRkHnvsMW8b+vXyzp49aw4cOGAOHDhgJJkVK1aYAwcOmBMnThhjeq4PX331VRMZGWl+9rOfmaNHj5olS5awtLe3WLlypbnuuutMdHS0ycrKMnv27LFdUq8hqd3jV7/6lbfNuXPnzA9+8ANz1VVXmbi4OPPNb37TnDx50ud5PvjgA3PXXXeZ2NhYk5SUZB555BFz4cIFnzavvPKKSU9PN9HR0WbYsGE+r9HftQ4j9GnX/PnPfzajR482DofDjBw50vzyl7/0edzj8ZhFixYZp9NpHA6HufPOO01lZaVPm//7v/8zU6dONQMGDDDx8fGmoKDAnD171qfNG2+8Ye644w7jcDhMamqqWb58edDfmy1ut9vMmzfPXHfddSYmJsYMGzbMLFiwwGf5KP16ea+88kq7/5bOmjXLGNOzffj73//efOUrXzHR0dHm5ptvNlu2bAna+w5UmDEtttMDAADoYSE5ZwQAAPQehBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABY9f+UHPx6vgzESgAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "2d9fcb6265879064",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T01:33:30.608061Z",
     "start_time": "2025-01-15T01:33:30.604074Z"
    }
   },
   "source": [
    "# problems\n",
    "# I didn't know how to find the data\n",
    "# getting the data from the csv was a hassle\n",
    "# had to use reciprocals to make the numbers smaller.\n",
    "# not enough epochs\n",
    "# 0.1 lr worked, but the learning rate only got up to 80. \n",
    "# I had a faulty accuracy function\n",
    "# non-linear layers did not help (relu)\n",
    "# issues with devices and converting to numpy for matplotlib"
   ],
   "outputs": [],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
