{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T23:04:28.408978Z",
     "start_time": "2024-11-20T23:04:28.402995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ],
   "id": "28edc5f42785b9ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T23:04:39.316606Z",
     "start_time": "2024-11-20T23:04:28.409975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import torch\n",
    "fileName = 'data/loan_data.csv'\n",
    "\n",
    "with open(fileName) as csvFile:\n",
    "    reader = csv.reader(csvFile)\n",
    "    variables = next(reader)\n",
    "    columnInfo = [[] for _ in range(len(variables))]\n",
    "    data = torch.tensor([])\n",
    "    labels = torch.tensor([])\n",
    "    for row in reader:\n",
    "        temp = torch.zeros(1, len(variables) - 1)\n",
    "        for columnIndex, column in enumerate(row[:-1]):\n",
    "            try:\n",
    "                value = float(column)\n",
    "            except ValueError:\n",
    "                if column not in columnInfo[columnIndex]:\n",
    "                    columnInfo[columnIndex].append(column)\n",
    "                value = columnInfo[columnIndex].index(column)\n",
    "            if value != 0:\n",
    "                value = value ** -1\n",
    "            temp[0][columnIndex] = value\n",
    "        data = torch.cat((data, temp))\n",
    "        labels = torch.cat((labels, torch.tensor([int(row[-1])])))\n",
    "labels = labels\n",
    "data.shape, labels.shape"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([45000, 13]), torch.Size([45000]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T23:04:39.337619Z",
     "start_time": "2024-11-20T23:04:39.317606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "df = df.set_axis(variables[:-1], axis=1)\n",
    "df"
   ],
   "id": "6cb129a90e9b70b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       person_age  person_gender  person_education  person_income  \\\n",
       "0        0.045455            0.0          0.000000       0.000014   \n",
       "1        0.047619            0.0          1.000000       0.000081   \n",
       "2        0.040000            0.0          1.000000       0.000080   \n",
       "3        0.043478            0.0          0.500000       0.000013   \n",
       "4        0.041667            1.0          0.000000       0.000015   \n",
       "...           ...            ...               ...            ...   \n",
       "44995    0.037037            1.0          0.333333       0.000021   \n",
       "44996    0.027027            0.0          0.333333       0.000015   \n",
       "44997    0.030303            1.0          0.333333       0.000018   \n",
       "44998    0.034483            1.0          0.500000       0.000030   \n",
       "44999    0.041667            1.0          1.000000       0.000019   \n",
       "\n",
       "       person_emp_exp  person_home_ownership  loan_amnt  loan_intent  \\\n",
       "0            0.000000                    0.0   0.000029         0.00   \n",
       "1            0.000000                    1.0   0.001000         1.00   \n",
       "2            0.333333                    0.5   0.000182         0.50   \n",
       "3            0.000000                    0.0   0.000029         0.50   \n",
       "4            1.000000                    0.0   0.000029         0.50   \n",
       "...               ...                    ...        ...          ...   \n",
       "44995        0.166667                    0.0   0.000067         0.50   \n",
       "44996        0.058824                    0.0   0.000111         0.25   \n",
       "44997        0.142857                    0.0   0.000361         0.20   \n",
       "44998        0.250000                    0.0   0.000083         1.00   \n",
       "44999        1.000000                    0.0   0.000150         0.20   \n",
       "\n",
       "       loan_int_rate  loan_percent_income  cb_person_cred_hist_length  \\\n",
       "0           0.062422             2.040816                    0.333333   \n",
       "1           0.089767            12.500000                    0.500000   \n",
       "2           0.077700             2.272727                    0.333333   \n",
       "3           0.065660             2.272727                    0.500000   \n",
       "4           0.070077             1.886792                    0.250000   \n",
       "...              ...                  ...                         ...   \n",
       "44995       0.063857             3.225806                    0.333333   \n",
       "44996       0.071073             7.142857                    0.090909   \n",
       "44997       0.099800            20.000000                    0.100000   \n",
       "44998       0.075586             2.777778                    0.166667   \n",
       "44999       0.058651             7.692307                    0.333333   \n",
       "\n",
       "       credit_score  previous_loan_defaults_on_file  \n",
       "0          0.001783                             0.0  \n",
       "1          0.001984                             1.0  \n",
       "2          0.001575                             0.0  \n",
       "3          0.001481                             0.0  \n",
       "4          0.001706                             0.0  \n",
       "...             ...                             ...  \n",
       "44995      0.001550                             0.0  \n",
       "44996      0.001610                             0.0  \n",
       "44997      0.001497                             0.0  \n",
       "44998      0.001656                             0.0  \n",
       "44999      0.001592                             0.0  \n",
       "\n",
       "[45000 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_gender</th>\n",
       "      <th>person_education</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_exp</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>previous_loan_defaults_on_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.062422</td>\n",
       "      <td>2.040816</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.089767</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.077700</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.065660</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.070077</td>\n",
       "      <td>1.886792</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44995</th>\n",
       "      <td>0.037037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.063857</td>\n",
       "      <td>3.225806</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44996</th>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.071073</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44997</th>\n",
       "      <td>0.030303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.099800</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44998</th>\n",
       "      <td>0.034483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.075586</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44999</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.058651</td>\n",
       "      <td>7.692307</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45000 rows × 13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T23:04:39.348289Z",
     "start_time": "2024-11-20T23:04:39.338619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pct = .8\n",
    "XSplit = int(pct*len(data))\n",
    "ySplit = int(pct * len(labels))\n",
    "XTrain, XTest = data[:XSplit].to(device), data[XSplit:].to(device)\n",
    "yTrain, yTest = labels[:ySplit].to(device), labels[ySplit:].to(device)\n",
    "XTrain.shape, XTest.shape, yTrain.shape, yTest.shape"
   ],
   "id": "948933f39b0ddeb8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([36000, 13]),\n",
       " torch.Size([9000, 13]),\n",
       " torch.Size([36000]),\n",
       " torch.Size([9000]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T23:04:39.364183Z",
     "start_time": "2024-11-20T23:04:39.349288Z"
    }
   },
   "cell_type": "code",
   "source": "XTrain[0:5], yTrain[0:5]",
   "id": "475ca1adbe7b3abb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4.5455e-02, 0.0000e+00, 0.0000e+00, 1.3899e-05, 0.0000e+00, 0.0000e+00,\n",
       "          2.8571e-05, 0.0000e+00, 6.2422e-02, 2.0408e+00, 3.3333e-01, 1.7825e-03,\n",
       "          0.0000e+00],\n",
       "         [4.7619e-02, 0.0000e+00, 1.0000e+00, 8.1420e-05, 0.0000e+00, 1.0000e+00,\n",
       "          1.0000e-03, 1.0000e+00, 8.9767e-02, 1.2500e+01, 5.0000e-01, 1.9841e-03,\n",
       "          1.0000e+00],\n",
       "         [4.0000e-02, 0.0000e+00, 1.0000e+00, 8.0399e-05, 3.3333e-01, 5.0000e-01,\n",
       "          1.8182e-04, 5.0000e-01, 7.7700e-02, 2.2727e+00, 3.3333e-01, 1.5748e-03,\n",
       "          0.0000e+00],\n",
       "         [4.3478e-02, 0.0000e+00, 5.0000e-01, 1.2539e-05, 0.0000e+00, 0.0000e+00,\n",
       "          2.8571e-05, 5.0000e-01, 6.5660e-02, 2.2727e+00, 5.0000e-01, 1.4815e-03,\n",
       "          0.0000e+00],\n",
       "         [4.1667e-02, 1.0000e+00, 0.0000e+00, 1.5121e-05, 1.0000e+00, 0.0000e+00,\n",
       "          2.8571e-05, 5.0000e-01, 7.0077e-02, 1.8868e+00, 2.5000e-01, 1.7065e-03,\n",
       "          0.0000e+00]], device='cuda:0'),\n",
       " tensor([1., 0., 1., 1., 1.], device='cuda:0'))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T23:04:41.436183Z",
     "start_time": "2024-11-20T23:04:39.365183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "class Model0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(13, 20)\n",
    "        self.layer2 = nn.Linear(20, 20)\n",
    "        self.layer3 = nn.Linear(20, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer3(self.relu(self.layer2(self.relu(self.layer1(x)))))\n",
    "model = Model0().to(device)\n",
    "lossFun = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters())\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    yLogits = model(XTrain).squeeze()\n",
    "    yPred = torch.round(torch.sigmoid(yLogits))\n",
    "    trainLoss = lossFun(yLogits, yTrain)\n",
    "    # acc = len(torch.unique(yLogits[testLogits == yTest])) / len(yTrain)\n",
    "    optimizer.zero_grad()\n",
    "    trainLoss.backward()\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        testLogits = model(XTest).squeeze()\n",
    "        testPred = torch.round(torch.sigmoid(testLogits))\n",
    "        testLoss = lossFun(testLogits, yTest)\n",
    "        testAcc = len(torch.unique(testPred[testPred == yTest])) / len(yTest)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:02} | Train loss: {trainLoss:.4f} | Test loss: {testLoss:.4f}  | Test acc: {testAcc*100:.4f}%')"
   ],
   "id": "ae6a24b124633f77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 | Train loss: 75720.3281 | Test loss: 1426660.5000  | Test acc: 0.0111%\n",
      "Epoch: 10 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 20 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 30 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 40 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 50 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 60 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 70 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 80 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 90 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 100 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 110 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 120 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 130 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 140 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 150 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 160 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 170 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 180 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 190 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 200 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 210 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 220 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 230 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 240 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 250 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 260 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 270 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 280 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 290 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 300 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 310 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 320 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 330 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 340 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 350 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 360 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 370 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 380 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 390 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 400 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 410 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 420 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 430 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 440 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 450 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 460 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 470 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 480 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 490 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 500 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 510 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 520 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 530 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 540 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 550 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 560 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 570 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 580 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 590 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 600 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 610 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 620 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 630 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 640 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 650 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 660 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 670 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 680 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 690 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 700 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 710 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 720 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 730 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 740 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 750 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 760 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 770 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 780 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 790 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 800 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 810 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 820 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 830 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 840 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 850 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 860 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 870 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 880 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 890 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 900 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 910 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 920 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 930 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 940 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 950 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 960 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 970 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 980 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n",
      "Epoch: 990 | Train loss: 74571.9688 | Test loss: 26331.5996  | Test acc: 0.0111%\n"
     ]
    }
   ],
   "execution_count": 92
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
